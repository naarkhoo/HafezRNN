{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HafezGar.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naarkhoo/HafezRNN/blob/master/HafezGar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "mBFfB8vLfqE4",
        "colab_type": "code",
        "outputId": "28684ba1-3778-42cf-816c-4d488ae152dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "!rm divan_hafez.txt\n",
        "!wget --show-progress --continue https://raw.githubusercontent.com/naarkhoo/HafezRNN/master/divan_hafez.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-07 20:46:41--  https://raw.githubusercontent.com/naarkhoo/HafezRNN/master/divan_hafez.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 593410 (580K) [text/plain]\n",
            "Saving to: ‘divan_hafez.txt’\n",
            "\n",
            "\rdivan_hafez.txt       0%[                    ]       0  --.-KB/s               \rdivan_hafez.txt     100%[===================>] 579.50K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2019-02-07 20:46:41 (11.1 MB/s) - ‘divan_hafez.txt’ saved [593410/593410]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G6CoXUNUHl5i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('divan_hafez.txt', 'rb') as f:\n",
        "  txt = f.read().decode(\"utf-16\")\n",
        "  txt = txt.replace(u'\\u200c','')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mD1clhMXbN9z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def remove_extra(txt):\n",
        "  b = ''\n",
        "  for item in txt.split('\\n'):\n",
        "    if item != '\\r':\n",
        "      b = item.replace('\\r', '') + b\n",
        "      #      a.append(item.replace('\\r', ''))\n",
        "  return(b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U-mctsqLkdRd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "\n",
        "# make everything number\n",
        "output = np.asarray([ord(c) for c in txt], dtype=np.int32)\n",
        "uvec = np.unique(output)\n",
        "\n",
        "asciicode2unique_d = {ni: indi for indi, ni in enumerate(set(uvec))}\n",
        "unique2asciicode_d = {y:x for x,y in asciicode2unique_d.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wOM1vTjc2MWD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e7e452e8-6bc8-4101-cce2-5bbca33a660c"
      },
      "cell_type": "code",
      "source": [
        "[asciicode2unique_d[ord(c)] for c in txt[0:10]] "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[26, 18, 29, 4, 4, 4, 38, 2, 1, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "lhv7qCLl7xC5",
        "colab_type": "code",
        "outputId": "921f8d2d-3550-4fa8-ac35-6bb1f8093758",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(set(uvec))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "M02Be-qmf4OI",
        "colab_type": "code",
        "outputId": "4c027037-a35e-4ee9-f411-c0a5ec7234d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9231
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import six\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import os\n",
        "\n",
        "# This address identifies the TPU we'll use when configuring TensorFlow.\n",
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "# SHAKESPEARE_TXT = '/content/shakespeare.txt'\n",
        "SHAKESPEARE_TXT = 'divan_hafez.txt'\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "def transform(txt, pad_to=None):\n",
        "  # drop any non-ascii characters\n",
        "  #output = np.asarray([ord(c) for c in txt if ord(c) < 255], dtype=np.int32)\n",
        "  txt = remove_extra(txt)\n",
        "  #output = np.asarray([ord(c) for c in txt], dtype=np.int32)\n",
        "  \n",
        "  output = np.asarray([asciicode2unique_d[ord(c)] for c in txt], dtype=np.int32)\n",
        "\n",
        "  if pad_to is not None:\n",
        "    output = output[:pad_to]\n",
        "    output = np.concatenate([\n",
        "        np.zeros([pad_to - len(txt)], dtype=np.int32),\n",
        "        output,\n",
        "    ])\n",
        "  return output\n",
        "\n",
        "def training_generator(seq_len=100, batch_size=1024):\n",
        "  \"\"\"A generator yields (source, target) arrays for training.\"\"\"\n",
        "  #with tf.gfile.GFile(SHAKESPEARE_TXT, 'r') as f:\n",
        "  #  txt = f.read()\n",
        "    \n",
        "  with open('divan_hafez.txt', 'rb') as f:\n",
        "    txt = f.read().decode(\"utf-16\")\n",
        "    txt = txt.replace(u'\\u200c','')\n",
        "     \n",
        "  tf.logging.info('Input text [%d] %s', len(txt), txt[:50])\n",
        "    \n",
        "  source = transform(txt)\n",
        "  while True:\n",
        "    offsets = np.random.randint(0, len(source) - seq_len, batch_size)\n",
        "\n",
        "    # Our model uses sparse crossentropy loss, but Keras requires labels\n",
        "    # to have the same rank as the input logits.  We add an empty final\n",
        "    # dimension to account for this.\n",
        "    yield (\n",
        "        np.stack([source[idx:idx + seq_len] for idx in offsets]),\n",
        "        np.expand_dims(\n",
        "            np.stack([source[idx + 1:idx + seq_len + 1] for idx in offsets]),\n",
        "            -1),\n",
        "    )\n",
        "\n",
        "six.next(training_generator(seq_len=100, batch_size=5))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Input text [295224] غزل   ۱\r\n",
            "\r\n",
            "الا يا ايها الساقی ادر کاسا و ناولها\r\n",
            "ک\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[33,  4,  8, 19,  4, 13, 28,  4, 14, 15, 30, 10,  4,  7, 19, 10,\n",
              "          6, 15, 30,  4,  8, 32, 20, 10,  4, 17, 33, 22, 32,  4, 15,  7,\n",
              "         17,  7, 29, 19, 29,  7, 30,  4, 17,  7, 15, 17,  4, 25, 34, 20,\n",
              "          4, 31, 28, 15,  4,  9, 33, 20,  4,  9, 32,  4,  0, 33, 31,  4,\n",
              "          6,  8, 14, 33, 17,  4, 31, 30,  7, 31, 15, 47, 34, 17,  7, 31,\n",
              "         32,  4, 19, 17,  4, 30,  9, 31,  4, 32, 31, 17, 35,  4, 31, 31,\n",
              "          5,  4, 33,  4],\n",
              "        [25, 29,  4,  7, 20,  9,  4, 15,  7, 17, 30,  4,  5, 31, 12, 32,\n",
              "          7, 10,  7,  4, 18,  4,  7, 20,  9,  4, 33,  4,  0, 32, 17, 32,\n",
              "          4, 17,  7, 32, 10,  4, 47, 17, 18, 17,  4, 33,  4,  5, 33, 32,\n",
              "         17,  4,  9, 31, 30,  8,  7, 18,  9, 20,  4, 34,  9,  4, 15, 30,\n",
              "          4, 25, 31,  7, 31,  4,  7, 35,  4, 10, 17,  9,  4, 20, 32, 17,\n",
              "          6, 20, 33,  8,  4, 30, 31, 15,  7, 33, 17, 35,  4, 15,  7, 17,\n",
              "         30,  4,  8, 19],\n",
              "        [17, 15, 30,  4,  0, 20, 30, 30,  4,  9, 32,  4,  8,  7,  4, 19,\n",
              "         34,  7, 32,  4, 15, 29, 35,  9, 32,  4, 17, 33, 18,  4,  8, 35,\n",
              "          9, 19, 35,  4,  6, 14, 17,  4, 31, 30, 35, 17, 33, 35,  4, 18,\n",
              "          4, 19, 17, 30,  0, 32,  4, 20,  9, 17,  4,  5, 33, 34, 30, 10,\n",
              "          4,  7, 35,  4, 14, 34, 29,  4, 26, 30,  4, 25, 27,  7,  9,  4,\n",
              "          7, 29, 29, 32,  9, 32,  4, 34,  9,  4, 31, 24, 17,  4, 27,  9,\n",
              "         31, 35,  4, 14],\n",
              "        [27, 10,  4,  8, 34,  7,  4, 10,  7,  4, 28, 22,  7,  4,  9, 31,\n",
              "         34, 30, 15, 17, 15, 32,  4, 28, 15, 13,  4,  9, 32,  4, 30, 33,\n",
              "         19, 30,  4, 31,  7, 30, 33, 19,  4, 33,  4, 31,  7, 30,  4, 17,\n",
              "         27, 10, 19,  7, 28, 35,  4,  8, 34,  7, 17,  4,  8,  7, 15, 32,\n",
              "          4,  9, 32,  4, 30,  7, 32,  4, 21, 34,  7, 30,  4, 17, 27, 10,\n",
              "         26, 18, 29,  4,  4,  4,  4, 45, 41, 47,  7, 35,  4,  6, 18,  7,\n",
              "         15, 35,  4,  0],\n",
              "        [19,  7, 31,  4,  5, 34, 17,  4,  8, 17,  4, 14, 33, 15,  4,  9,\n",
              "          7, 17, 32,  7,  4,  9, 18,  4, 17, 33, 35,  4, 23,  8, 25, 33,\n",
              "          4,  7, 18,  4, 20, 30,  7,  4, 47, 31, 32,  7, 31,  4, 31, 20,\n",
              "          7, 34, 15,  4,  9, 17, 15,  4, 19, 17,  4, 30, 35,  4, 27, 17,\n",
              "         33, 20, 15, 33, 20,  4,  8,  7,  4, 30, 31,  4,  5, 27, 10,  4,\n",
              "         47, 31, 32,  7, 31,  4,  9,  7, 17, 15,  7, 31, 35,  4, 10, 34,\n",
              "         18, 32, 33, 20]], dtype=int32), array([[[ 4],\n",
              "         [ 8],\n",
              "         [19],\n",
              "         [ 4],\n",
              "         [13],\n",
              "         [28],\n",
              "         [ 4],\n",
              "         [14],\n",
              "         [15],\n",
              "         [30],\n",
              "         [10],\n",
              "         [ 4],\n",
              "         [ 7],\n",
              "         [19],\n",
              "         [10],\n",
              "         [ 6],\n",
              "         [15],\n",
              "         [30],\n",
              "         [ 4],\n",
              "         [ 8],\n",
              "         [32],\n",
              "         [20],\n",
              "         [10],\n",
              "         [ 4],\n",
              "         [17],\n",
              "         [33],\n",
              "         [22],\n",
              "         [32],\n",
              "         [ 4],\n",
              "         [15],\n",
              "         [ 7],\n",
              "         [17],\n",
              "         [ 7],\n",
              "         [29],\n",
              "         [19],\n",
              "         [29],\n",
              "         [ 7],\n",
              "         [30],\n",
              "         [ 4],\n",
              "         [17],\n",
              "         [ 7],\n",
              "         [15],\n",
              "         [17],\n",
              "         [ 4],\n",
              "         [25],\n",
              "         [34],\n",
              "         [20],\n",
              "         [ 4],\n",
              "         [31],\n",
              "         [28],\n",
              "         [15],\n",
              "         [ 4],\n",
              "         [ 9],\n",
              "         [33],\n",
              "         [20],\n",
              "         [ 4],\n",
              "         [ 9],\n",
              "         [32],\n",
              "         [ 4],\n",
              "         [ 0],\n",
              "         [33],\n",
              "         [31],\n",
              "         [ 4],\n",
              "         [ 6],\n",
              "         [ 8],\n",
              "         [14],\n",
              "         [33],\n",
              "         [17],\n",
              "         [ 4],\n",
              "         [31],\n",
              "         [30],\n",
              "         [ 7],\n",
              "         [31],\n",
              "         [15],\n",
              "         [47],\n",
              "         [34],\n",
              "         [17],\n",
              "         [ 7],\n",
              "         [31],\n",
              "         [32],\n",
              "         [ 4],\n",
              "         [19],\n",
              "         [17],\n",
              "         [ 4],\n",
              "         [30],\n",
              "         [ 9],\n",
              "         [31],\n",
              "         [ 4],\n",
              "         [32],\n",
              "         [31],\n",
              "         [17],\n",
              "         [35],\n",
              "         [ 4],\n",
              "         [31],\n",
              "         [31],\n",
              "         [ 5],\n",
              "         [ 4],\n",
              "         [33],\n",
              "         [ 4],\n",
              "         [31]],\n",
              " \n",
              "        [[29],\n",
              "         [ 4],\n",
              "         [ 7],\n",
              "         [20],\n",
              "         [ 9],\n",
              "         [ 4],\n",
              "         [15],\n",
              "         [ 7],\n",
              "         [17],\n",
              "         [30],\n",
              "         [ 4],\n",
              "         [ 5],\n",
              "         [31],\n",
              "         [12],\n",
              "         [32],\n",
              "         [ 7],\n",
              "         [10],\n",
              "         [ 7],\n",
              "         [ 4],\n",
              "         [18],\n",
              "         [ 4],\n",
              "         [ 7],\n",
              "         [20],\n",
              "         [ 9],\n",
              "         [ 4],\n",
              "         [33],\n",
              "         [ 4],\n",
              "         [ 0],\n",
              "         [32],\n",
              "         [17],\n",
              "         [32],\n",
              "         [ 4],\n",
              "         [17],\n",
              "         [ 7],\n",
              "         [32],\n",
              "         [10],\n",
              "         [ 4],\n",
              "         [47],\n",
              "         [17],\n",
              "         [18],\n",
              "         [17],\n",
              "         [ 4],\n",
              "         [33],\n",
              "         [ 4],\n",
              "         [ 5],\n",
              "         [33],\n",
              "         [32],\n",
              "         [17],\n",
              "         [ 4],\n",
              "         [ 9],\n",
              "         [31],\n",
              "         [30],\n",
              "         [ 8],\n",
              "         [ 7],\n",
              "         [18],\n",
              "         [ 9],\n",
              "         [20],\n",
              "         [ 4],\n",
              "         [34],\n",
              "         [ 9],\n",
              "         [ 4],\n",
              "         [15],\n",
              "         [30],\n",
              "         [ 4],\n",
              "         [25],\n",
              "         [31],\n",
              "         [ 7],\n",
              "         [31],\n",
              "         [ 4],\n",
              "         [ 7],\n",
              "         [35],\n",
              "         [ 4],\n",
              "         [10],\n",
              "         [17],\n",
              "         [ 9],\n",
              "         [ 4],\n",
              "         [20],\n",
              "         [32],\n",
              "         [17],\n",
              "         [ 6],\n",
              "         [20],\n",
              "         [33],\n",
              "         [ 8],\n",
              "         [ 4],\n",
              "         [30],\n",
              "         [31],\n",
              "         [15],\n",
              "         [ 7],\n",
              "         [33],\n",
              "         [17],\n",
              "         [35],\n",
              "         [ 4],\n",
              "         [15],\n",
              "         [ 7],\n",
              "         [17],\n",
              "         [30],\n",
              "         [ 4],\n",
              "         [ 8],\n",
              "         [19],\n",
              "         [35]],\n",
              " \n",
              "        [[15],\n",
              "         [30],\n",
              "         [ 4],\n",
              "         [ 0],\n",
              "         [20],\n",
              "         [30],\n",
              "         [30],\n",
              "         [ 4],\n",
              "         [ 9],\n",
              "         [32],\n",
              "         [ 4],\n",
              "         [ 8],\n",
              "         [ 7],\n",
              "         [ 4],\n",
              "         [19],\n",
              "         [34],\n",
              "         [ 7],\n",
              "         [32],\n",
              "         [ 4],\n",
              "         [15],\n",
              "         [29],\n",
              "         [35],\n",
              "         [ 9],\n",
              "         [32],\n",
              "         [ 4],\n",
              "         [17],\n",
              "         [33],\n",
              "         [18],\n",
              "         [ 4],\n",
              "         [ 8],\n",
              "         [35],\n",
              "         [ 9],\n",
              "         [19],\n",
              "         [35],\n",
              "         [ 4],\n",
              "         [ 6],\n",
              "         [14],\n",
              "         [17],\n",
              "         [ 4],\n",
              "         [31],\n",
              "         [30],\n",
              "         [35],\n",
              "         [17],\n",
              "         [33],\n",
              "         [35],\n",
              "         [ 4],\n",
              "         [18],\n",
              "         [ 4],\n",
              "         [19],\n",
              "         [17],\n",
              "         [30],\n",
              "         [ 0],\n",
              "         [32],\n",
              "         [ 4],\n",
              "         [20],\n",
              "         [ 9],\n",
              "         [17],\n",
              "         [ 4],\n",
              "         [ 5],\n",
              "         [33],\n",
              "         [34],\n",
              "         [30],\n",
              "         [10],\n",
              "         [ 4],\n",
              "         [ 7],\n",
              "         [35],\n",
              "         [ 4],\n",
              "         [14],\n",
              "         [34],\n",
              "         [29],\n",
              "         [ 4],\n",
              "         [26],\n",
              "         [30],\n",
              "         [ 4],\n",
              "         [25],\n",
              "         [27],\n",
              "         [ 7],\n",
              "         [ 9],\n",
              "         [ 4],\n",
              "         [ 7],\n",
              "         [29],\n",
              "         [29],\n",
              "         [32],\n",
              "         [ 9],\n",
              "         [32],\n",
              "         [ 4],\n",
              "         [34],\n",
              "         [ 9],\n",
              "         [ 4],\n",
              "         [31],\n",
              "         [24],\n",
              "         [17],\n",
              "         [ 4],\n",
              "         [27],\n",
              "         [ 9],\n",
              "         [31],\n",
              "         [35],\n",
              "         [ 4],\n",
              "         [14],\n",
              "         [33]],\n",
              " \n",
              "        [[10],\n",
              "         [ 4],\n",
              "         [ 8],\n",
              "         [34],\n",
              "         [ 7],\n",
              "         [ 4],\n",
              "         [10],\n",
              "         [ 7],\n",
              "         [ 4],\n",
              "         [28],\n",
              "         [22],\n",
              "         [ 7],\n",
              "         [ 4],\n",
              "         [ 9],\n",
              "         [31],\n",
              "         [34],\n",
              "         [30],\n",
              "         [15],\n",
              "         [17],\n",
              "         [15],\n",
              "         [32],\n",
              "         [ 4],\n",
              "         [28],\n",
              "         [15],\n",
              "         [13],\n",
              "         [ 4],\n",
              "         [ 9],\n",
              "         [32],\n",
              "         [ 4],\n",
              "         [30],\n",
              "         [33],\n",
              "         [19],\n",
              "         [30],\n",
              "         [ 4],\n",
              "         [31],\n",
              "         [ 7],\n",
              "         [30],\n",
              "         [33],\n",
              "         [19],\n",
              "         [ 4],\n",
              "         [33],\n",
              "         [ 4],\n",
              "         [31],\n",
              "         [ 7],\n",
              "         [30],\n",
              "         [ 4],\n",
              "         [17],\n",
              "         [27],\n",
              "         [10],\n",
              "         [19],\n",
              "         [ 7],\n",
              "         [28],\n",
              "         [35],\n",
              "         [ 4],\n",
              "         [ 8],\n",
              "         [34],\n",
              "         [ 7],\n",
              "         [17],\n",
              "         [ 4],\n",
              "         [ 8],\n",
              "         [ 7],\n",
              "         [15],\n",
              "         [32],\n",
              "         [ 4],\n",
              "         [ 9],\n",
              "         [32],\n",
              "         [ 4],\n",
              "         [30],\n",
              "         [ 7],\n",
              "         [32],\n",
              "         [ 4],\n",
              "         [21],\n",
              "         [34],\n",
              "         [ 7],\n",
              "         [30],\n",
              "         [ 4],\n",
              "         [17],\n",
              "         [27],\n",
              "         [10],\n",
              "         [26],\n",
              "         [18],\n",
              "         [29],\n",
              "         [ 4],\n",
              "         [ 4],\n",
              "         [ 4],\n",
              "         [ 4],\n",
              "         [45],\n",
              "         [41],\n",
              "         [47],\n",
              "         [ 7],\n",
              "         [35],\n",
              "         [ 4],\n",
              "         [ 6],\n",
              "         [18],\n",
              "         [ 7],\n",
              "         [15],\n",
              "         [35],\n",
              "         [ 4],\n",
              "         [ 0],\n",
              "         [32]],\n",
              " \n",
              "        [[ 7],\n",
              "         [31],\n",
              "         [ 4],\n",
              "         [ 5],\n",
              "         [34],\n",
              "         [17],\n",
              "         [ 4],\n",
              "         [ 8],\n",
              "         [17],\n",
              "         [ 4],\n",
              "         [14],\n",
              "         [33],\n",
              "         [15],\n",
              "         [ 4],\n",
              "         [ 9],\n",
              "         [ 7],\n",
              "         [17],\n",
              "         [32],\n",
              "         [ 7],\n",
              "         [ 4],\n",
              "         [ 9],\n",
              "         [18],\n",
              "         [ 4],\n",
              "         [17],\n",
              "         [33],\n",
              "         [35],\n",
              "         [ 4],\n",
              "         [23],\n",
              "         [ 8],\n",
              "         [25],\n",
              "         [33],\n",
              "         [ 4],\n",
              "         [ 7],\n",
              "         [18],\n",
              "         [ 4],\n",
              "         [20],\n",
              "         [30],\n",
              "         [ 7],\n",
              "         [ 4],\n",
              "         [47],\n",
              "         [31],\n",
              "         [32],\n",
              "         [ 7],\n",
              "         [31],\n",
              "         [ 4],\n",
              "         [31],\n",
              "         [20],\n",
              "         [ 7],\n",
              "         [34],\n",
              "         [15],\n",
              "         [ 4],\n",
              "         [ 9],\n",
              "         [17],\n",
              "         [15],\n",
              "         [ 4],\n",
              "         [19],\n",
              "         [17],\n",
              "         [ 4],\n",
              "         [30],\n",
              "         [35],\n",
              "         [ 4],\n",
              "         [27],\n",
              "         [17],\n",
              "         [33],\n",
              "         [20],\n",
              "         [15],\n",
              "         [33],\n",
              "         [20],\n",
              "         [ 4],\n",
              "         [ 8],\n",
              "         [ 7],\n",
              "         [ 4],\n",
              "         [30],\n",
              "         [31],\n",
              "         [ 4],\n",
              "         [ 5],\n",
              "         [27],\n",
              "         [10],\n",
              "         [ 4],\n",
              "         [47],\n",
              "         [31],\n",
              "         [32],\n",
              "         [ 7],\n",
              "         [31],\n",
              "         [ 4],\n",
              "         [ 9],\n",
              "         [ 7],\n",
              "         [17],\n",
              "         [15],\n",
              "         [ 7],\n",
              "         [31],\n",
              "         [35],\n",
              "         [ 4],\n",
              "         [10],\n",
              "         [34],\n",
              "         [18],\n",
              "         [32],\n",
              "         [33],\n",
              "         [20],\n",
              "         [26]]], dtype=int32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "DkX9k8bAgFUg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 512\n",
        "\n",
        "def lstm_model(seq_len=100, batch_size=None, stateful=True):\n",
        "  \"\"\"Language model: predict the next word given the current word.\"\"\"\n",
        "  source = tf.keras.Input(\n",
        "      name='seed', shape=(seq_len,), batch_size=batch_size, dtype=tf.int32)\n",
        "\n",
        "  #embedding = tf.keras.layers.Embedding(input_dim=256, output_dim=EMBEDDING_DIM)(source)\n",
        "  embedding = tf.keras.layers.Embedding(input_dim=50, output_dim=EMBEDDING_DIM)(source)\n",
        "  \n",
        "  lstm_1 = tf.keras.layers.LSTM(EMBEDDING_DIM, stateful=stateful, return_sequences=True)(embedding)\n",
        "  lstm_2 = tf.keras.layers.LSTM(EMBEDDING_DIM, stateful=stateful, return_sequences=True)(lstm_1)\n",
        "#  predicted_char = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(256, activation='softmax'))(lstm_2)\n",
        "  predicted_char = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(50, activation='softmax'))(lstm_2)\n",
        "  model = tf.keras.Model(inputs=[source], outputs=[predicted_char])\n",
        "  model.compile(\n",
        "      optimizer=tf.train.RMSPropOptimizer(learning_rate=0.01),\n",
        "      loss='sparse_categorical_crossentropy',\n",
        "      metrics=['sparse_categorical_accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WyZpg4IFgJYp",
        "colab_type": "code",
        "outputId": "7a10ab83-a59c-4d61-8977-1b35b1db2b03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1125
        }
      },
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "training_model = lstm_model(seq_len=100, batch_size=128, stateful=False)\n",
        "\n",
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    training_model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\n",
        "\n",
        "tpu_model.fit_generator(\n",
        "    training_generator(seq_len=100, batch_size=1024),\n",
        "    steps_per_epoch=100,\n",
        "    epochs=10,\n",
        ")\n",
        "tpu_model.save_weights('/tmp/bard_hafez.h5', overwrite=True)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.69.29.114:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 4595241092013431743)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 15567322301889423376)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 16675418112568878402)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 18034971188277535635)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 18169048755005212276)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 1007337382635077569)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 13001253714104840072)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 11916530324678358515)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3226992851983750856)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 11224806797038299827)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 16336874119119851668)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "Epoch 1/10\n",
            "INFO:tensorflow:Input text [295224] غزل   ۱\n",
            "\n",
            "الا يا ايها الساقی ادر کاسا و ناولها\n",
            "ک\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(128,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(128, 100), dtype=tf.int32, name='seed_10'), TensorSpec(shape=(128, 100, 1), dtype=tf.int32, name='time_distributed_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for seed\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 8.351919651031494 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "100/100 [==============================] - 34s 342ms/step - loss: 3.4305 - sparse_categorical_accuracy: 0.1977\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 14s 141ms/step - loss: 3.1027 - sparse_categorical_accuracy: 0.2117\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 14s 142ms/step - loss: 2.9784 - sparse_categorical_accuracy: 0.2107\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 14s 143ms/step - loss: 2.3600 - sparse_categorical_accuracy: 0.3456\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 14s 143ms/step - loss: 1.8890 - sparse_categorical_accuracy: 0.4563\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 14s 142ms/step - loss: 1.5440 - sparse_categorical_accuracy: 0.5417\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 14s 142ms/step - loss: 1.1222 - sparse_categorical_accuracy: 0.6611\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 14s 143ms/step - loss: 0.7233 - sparse_categorical_accuracy: 0.7847\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 14s 143ms/step - loss: 0.4663 - sparse_categorical_accuracy: 0.8666\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 14s 142ms/step - loss: 0.3645 - sparse_categorical_accuracy: 0.8987\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7UVVK8NagPL3",
        "colab_type": "code",
        "outputId": "0bf058c3-f6d2-4051-afbb-8e65e12b8c67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 5\n",
        "PREDICT_LEN = 45\n",
        "\n",
        "# Keras requires the batch size be specified ahead of time for stateful models.\n",
        "# We use a sequence length of 1, as we will be feeding in one character at a \n",
        "# time and predicting the next character.\n",
        "prediction_model = lstm_model(seq_len=1, batch_size=BATCH_SIZE, stateful=True)\n",
        "prediction_model.load_weights('/tmp/bard_hafez.h5')\n",
        "\n",
        "# We seed the model with our initial string, copied BATCH_SIZE times\n",
        "\n",
        "seed_txt = 'الا یا ایه الساقی'\n",
        "\n",
        "print(type(seed_txt))\n",
        "seed = transform(seed_txt)\n",
        "seed = np.repeat(np.expand_dims(seed, 0), BATCH_SIZE, axis=0)\n",
        "print(seed)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'str'>\n",
            "[[ 7 29  7  4 35  7  4  7 35 32  4  7 29 19  7 28 35]\n",
            " [ 7 29  7  4 35  7  4  7 35 32  4  7 29 19  7 28 35]\n",
            " [ 7 29  7  4 35  7  4  7 35 32  4  7 29 19  7 28 35]\n",
            " [ 7 29  7  4 35  7  4  7 35 32  4  7 29 19  7 28 35]\n",
            " [ 7 29  7  4 35  7  4  7 35 32  4  7 29 19  7 28 35]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VgMd1h3HzVRN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(len(seed_txt)-1):\n",
        "  prediction_model.predict(seed[:, i:i + 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yhd8srP_muRz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# First, run the seed forward to prime the state of the model.\n",
        "prediction_model.reset_states()\n",
        "for i in range(len(seed_txt) - 1):\n",
        "  prediction_model.predict(seed[:, i:i + 1])\n",
        "\n",
        "# Now we can accumulate predictions!\n",
        "predictions = [seed[:, -1:]]\n",
        "for i in range(PREDICT_LEN):\n",
        "  last_word = predictions[-1]\n",
        "  next_probits = prediction_model.predict(last_word)[:, 0, :]\n",
        "  \n",
        "  # sample from our output distribution\n",
        "  next_idx = [\n",
        "      np.random.choice(50, p=next_probits[i])\n",
        "      for i in range(BATCH_SIZE)\n",
        "  ]\n",
        "  predictions.append(np.asarray(next_idx, dtype=np.int32))\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kwxGTua0mWzS",
        "colab_type": "code",
        "outputId": "d2a0b402-5160-470b-8bef-fa474bf5ee2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(BATCH_SIZE):\n",
        "  print('PREDICTION %d\\n\\n' % i)\n",
        "  p = [predictions[j][i] for j in range(PREDICT_LEN)]\n",
        "  #print(p)\n",
        "  print(''.join([str(chr(unique2asciicode_d[item])) for item in p[1::]]))\n",
        "  generated = ''.join([chr(c) for c in p])\n",
        "  print(generated)\n",
        "  assert len(generated) == PREDICT_LEN, 'Generated text too short'"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PREDICTION 0\n",
            "\n",
            "\n",
            " می با فلک و کشتی هر آن کس که کمان ابروی ميخ\n",
            "#\u0004\u001e#\u0004\b\u0007\u0004\u001b\u001d\t\u0004!\u0004\t\u0014\n",
            "#\u0004 \u0011\u0004\u0006\u001f\u0004\t\u0013\u0004\t \u0004\t\u001e\u0007\u001f\u0004\u0007\b\u0011!#\u0004\u001e\"\u000e\n",
            "PREDICTION 1\n",
            "\n",
            "\n",
            " مدارجهان عيب خود خوشش باش که خيری به جای خو\n",
            "#\u0004\u001e\u000f\u0007\u0011\f \u0007\u001f\u0004\u0019\"\b\u0004\u000e!\u000f\u0004\u000e!\u0014\u0014\u0004\b\u0007\u0014\u0004\t \u0004\u000e\"\u0011#\u0004\b \u0004\f\u0007#\u0004\u000e!\n",
            "PREDICTION 2\n",
            "\n",
            "\n",
            " مدار همعزم دراز که بردارد زمانی برقع از روي\n",
            "#\u0004\u001e\u000f\u0007\u0011\u0004 \u001e\u0019\u0012\u001e\u0004\u000f\u0011\u0007\u0012\u0004\t \u0004\b\u0011\u000f\u0007\u0011\u000f\u0004\u0012\u001e\u0007\u001f#\u0004\b\u0011\u001c\u0019\u0004\u0007\u0012\u0004\u0011!\"\n",
            "PREDICTION 3\n",
            "\n",
            "\n",
            " مدار کجاستآن کس است اهل رخشان به جای من سرو\n",
            "#\u0004\u001e\u000f\u0007\u0011\u0004\t\f\u0007\u0013\n",
            "\u0006\u001f\u0004\t\u0013\u0004\u0007\u0013\n",
            "\u0004\u0007 \u001d\u0004\u0011\u000e\u0014\u0007\u001f\u0004\b \u0004\f\u0007#\u0004\u001e\u001f\u0004\u0013\u0011!\n",
            "PREDICTION 4\n",
            "\n",
            "\n",
            " که مهمت است آب روان آيد و بلاکش باشدغزل    \n",
            "#\u0004\t \u0004\u001e \u001e\n",
            "\u0004\u0007\u0013\n",
            "\u0004\u0006\b\u0004\u0011!\u0007\u001f\u0004\u0006\"\u000f\u0004!\u0004\b\u001d\u0007\t\u0014\u0004\b\u0007\u0014\u000f\u001a\u0012\u001d\u0004\u0004\u0004\u0004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fGEQSF-VXv1W",
        "colab_type": "code",
        "outputId": "932b888b-5d0d-4f11-91fd-83e3656214f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'کند\\r\\n\\r\\nغبار دارد که فلک '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "gCVEh84aLjxs",
        "colab_type": "code",
        "outputId": "45108162-1edc-46c1-a842-b406a9a8c6d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        }
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 5\n",
        "PREDICT_LEN = 250\n",
        "\n",
        "# Keras requires the batch size be specified ahead of time for stateful models.\n",
        "# We use a sequence length of 1, as we will be feeding in one character at a \n",
        "# time and predicting the next character.\n",
        "prediction_model = lstm_model(seq_len=1, batch_size=BATCH_SIZE, stateful=True)\n",
        "prediction_model.load_weights('/tmp/bard.h5')\n",
        "\n",
        "# We seed the model with our initial string, copied BATCH_SIZE times\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-7f5a70624763>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# time and predicting the next character.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprediction_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstateful\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprediction_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/tmp/bard.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# We seed the model with our initial string, copied BATCH_SIZE times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   1508\u001b[0m           \u001b[0;34m'Model which has not created its variables yet. Call the Model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m           'first, then load the weights.')\n\u001b[0;32m-> 1510\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1511\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1512\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '/tmp/bard.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "hNyjkEdXQ8B5",
        "colab_type": "code",
        "outputId": "b8a99bb8-d751-4fc4-bc6d-0afa7f23261f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "cell_type": "code",
      "source": [
        "seed_txt = 'Looks it not like the king?  Verily, we must go! '\n",
        "#seed_txt = 'الساقی ادر کاسا و ناولها'\n",
        "\n",
        "seed = transform(seed_txt)\n",
        "seed = np.repeat(np.expand_dims(seed, 0), BATCH_SIZE, axis=0)\n",
        "seed"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 76, 111, 111, 107, 115,  32, 105, 116,  32, 110, 111, 116,  32,\n",
              "        108, 105, 107, 101,  32, 116, 104, 101,  32, 107, 105, 110, 103,\n",
              "         63,  32,  32,  86, 101, 114, 105, 108, 121,  44,  32, 119, 101,\n",
              "         32, 109, 117, 115, 116,  32, 103, 111,  33,  32],\n",
              "       [ 76, 111, 111, 107, 115,  32, 105, 116,  32, 110, 111, 116,  32,\n",
              "        108, 105, 107, 101,  32, 116, 104, 101,  32, 107, 105, 110, 103,\n",
              "         63,  32,  32,  86, 101, 114, 105, 108, 121,  44,  32, 119, 101,\n",
              "         32, 109, 117, 115, 116,  32, 103, 111,  33,  32],\n",
              "       [ 76, 111, 111, 107, 115,  32, 105, 116,  32, 110, 111, 116,  32,\n",
              "        108, 105, 107, 101,  32, 116, 104, 101,  32, 107, 105, 110, 103,\n",
              "         63,  32,  32,  86, 101, 114, 105, 108, 121,  44,  32, 119, 101,\n",
              "         32, 109, 117, 115, 116,  32, 103, 111,  33,  32],\n",
              "       [ 76, 111, 111, 107, 115,  32, 105, 116,  32, 110, 111, 116,  32,\n",
              "        108, 105, 107, 101,  32, 116, 104, 101,  32, 107, 105, 110, 103,\n",
              "         63,  32,  32,  86, 101, 114, 105, 108, 121,  44,  32, 119, 101,\n",
              "         32, 109, 117, 115, 116,  32, 103, 111,  33,  32],\n",
              "       [ 76, 111, 111, 107, 115,  32, 105, 116,  32, 110, 111, 116,  32,\n",
              "        108, 105, 107, 101,  32, 116, 104, 101,  32, 107, 105, 110, 103,\n",
              "         63,  32,  32,  86, 101, 114, 105, 108, 121,  44,  32, 119, 101,\n",
              "         32, 109, 117, 115, 116,  32, 103, 111,  33,  32]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "ZtgfZNc0L_7J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# First, run the seed forward to prime the state of the model.\n",
        "prediction_model.reset_states()\n",
        "for i in range(len(seed_txt) - 1):\n",
        "  prediction_model.predict(seed[:, i:i + 1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vvN0fyzYKSPV",
        "colab_type": "code",
        "outputId": "df1d5eb7-6f4a-4940-ead7-59ecc6c60216",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "with open('divan_hafez.txt', 'rb') as f:\n",
        "  contents = f.read()\n",
        "  contents = contents.decode(\"utf-16\")\n",
        "\n",
        "bb = contents.replace(u'\\u200c','')\n",
        "bb[1:50]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'زل   ۱\\r\\n\\r\\nالا يا ايها الساقی ادر کاسا و ناولها\\r\\nک'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    }
  ]
}